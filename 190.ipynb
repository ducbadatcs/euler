{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sum_{i=1}^m x_i = m \\Rightarrow \\max P_m = \\prod_{i=1}^m {x_i}^i = ?$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the [Weighted AM-GM Inequality](https://en.wikipedia.org/wiki/AM%E2%80%93GM_inequality#Weighted_AM%E2%80%93GM_inequality) and set the weights $w_i =  i$ for each case. Then $$w = \\sum_{i = 1}^m w_i = \\sum_{i = 1}^m i = \\frac{m(m + 1)}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and \n",
    "$$\n",
    "\\displaystyle{P_m = \\prod_{i=1} {x_i}^i \\Rightarrow {P_m}^{\\frac{1}{w}} = \\sqrt[w]{\\prod_{i=1} {x_i}^i} \\leq \\frac{\\sum_{i=1}^m w_i x_i}{w} = \\frac{\\sum_{i=1}^m i x_i}{w}} \\\\~\\\\\n",
    "\n",
    "= \\frac{1}{w} \\sum_{i=1}^m i x_i\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in other words the max value of $P_m$ is $\\displaystyle{\\left(\\frac{1}{w} \\sum_{i=1}^m ix_i\\right)^w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is hard to visualize, let's write it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "m = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.2982925569784243)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pow(4112, 1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla f\\left(\\left[ x_1, \\ \\dots, \\ x_n \\right]\\right) = \\begin{bmatrix} \\frac{\\partial}{\\partial x_1} f(p) \\\\~\\\\ \\dots \\\\~\\\\ \\frac{\\partial}{\\partial x_n} f(p) \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def derivative(f: Callable[[float], float], x: float) -> float:\n",
    "    eps = 1e-7\n",
    "    return (f(x + eps) - f(x)) / eps\n",
    "\n",
    "\n",
    "def gradient(f: Callable[[np.ndarray], np.ndarray], x: np.ndarray) -> np.ndarray:\n",
    "    eps = 1e-8\n",
    "    for i in range(len(x)):\n",
    "        v = []\n",
    "        y = np.array(x)\n",
    "        y[i] += eps\n",
    "        v.append((f(y) - f(x)) / eps)\n",
    "    return np.array(v)\n",
    "\n",
    "gradient(np.cos, [0, np.pi / 2, np.pi])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_{i=1}^m x_i = m \\Rightarrow P_m(x) = \\prod_{i=1}^m {x_i}^i = ? \\\\~\\\\\n",
    "\\ln P_m(x) = \\sum_{i=1}^n i \\ln(x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_P(x: np.ndarray) -> float:\n",
    "    return np.dot(np.arange(1, len(x) + 1), x)\n",
    "\n",
    "def P(x: np.ndarray) -> float:\n",
    "    return np.exp(ln_P(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "lagrange\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def P_minima(x0: np.ndarray, lr: float = 0.01) -> np.ndarray:\n",
    "    for _ in range(10000):\n",
    "        z = gradient(ln_P(x))        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so @griff and @hacatu made me read about the Lagrange Multiplier\n",
    "\n",
    "We have $m$ variables and one constraint, so we define a single $\\lambda$\n",
    "\n",
    "We have $$P(x_1, x_2, \\dots, x_m) = \\prod_{i=1}^m x_i^i$$ subject to $g(x_1, x_2, \\dots, x_m) = \\sum_{i=1}^m x_i - m = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly we don't have the Laplace transform symbol used in Wikipedia so we use the letter $L$ instead\n",
    "\n",
    "$$\n",
    "L(x_1, x_2, \\dots, x_m, \\lambda) = P(x_1, x_2, \\dots, x_m) + \\lambda g(x_1, x_2, \\dots, x_m) \\\\~\\\\\n",
    "= \\prod_{i=1}^m x_i^i + \\lambda\\left(\\sum_{i=1}^m x_i - m\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now  we can calculate the gradient\n",
    "\n",
    "$$\n",
    "\\nabla_{x_1, x_2, \\dots, x_m, \\lambda} L(x_1, x_2, \\dots, x_m, \\lambda) = \\left(\\frac{\\partial L}{\\partial x_1}, \\frac{\\partial L}{\\partial x_2}, \\dots, \\frac{\\partial L}{\\partial \\lambda}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but first, we redefine thd derivative of a power a bit:\n",
    "\n",
    "$$\n",
    "\\frac{\\text{ d}}{\\text{ d}x} x^n = nx^{n-1} = \\frac{n}{x} x^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we calculate the entrywise derivatives, for $1 \\leq a \\leq m$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial P}{\\partial x_a} = \\frac{\\partial }{\\partial x_a}\\left(\\prod_{i=1}^m x_i^i\\right) = \\frac{a}{x_a} \\prod_{i=1}^m x_i^i \\\\~\\\\\n",
    "\\frac{\\partial g}{\\partial x_a} = \\frac{\\partial }{\\partial x_a}\\left(\\sum_{i=1}^m x_i - m\\right) = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla_{x_1, x_2, \\dots, x_m, \\lambda} L(x_1, x_2, \\dots, x_m, \\lambda) = \\left(\\frac{1}{x_1} \\prod_{i=1}^m x_i^i + \\lambda, \\frac{2}{x_2} \\prod_{i=1}^m x_i^i + \\lambda, \\dots, \\frac{m}{x_m} \\prod_{i=1}^m x_i^i + \\lambda, \\sum_{i=1}^m x_i - m \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the $\\nabla = 0$:\n",
    "\n",
    "$$\n",
    "\\nabla_{x_1, x_2, \\dots, x_m, \\lambda} L(x_1, x_2, \\dots, x_m, \\lambda) = 0 \\Rightarrow \n",
    "\\begin{cases}\n",
    "\\frac{1}{x_1} \\prod_{i=1}^m x_i^i + \\lambda = 0 \\\\\n",
    "\\frac{2}{x_2} \\prod_{i=1}^m x_i^i + \\lambda = 0 \\\\\n",
    "\\dots \\\\\n",
    "\\frac{m}{x_m} \\prod_{i=1}^m x_i^i + \\lambda = 0\\\\\n",
    "\\sum_{i=1}^m x_i - m = 0\n",
    "\\end{cases} \\\\~\\\\\n",
    "\\Rightarrow \\frac{1}{x_1} \\prod_{i=1}^m x_i^i = \\frac{2}{x_2} \\prod_{i=1}^m x_i^i = \\dots = \\frac{m}{x_m} \\prod_{i=1}^m x_i^i = -\\lambda \\\\~\\\\\n",
    "\\Rightarrow \\frac{1}{x_1} = \\frac{2}{x_2} = \\dots = \\frac{m}{x_m} \\Rightarrow \\frac{x_1}{1} = \\frac{x_2}{2} = \\dots = \\frac{x_m}{m}\n",
    "$$\n",
    "\n",
    "Combine this with the other condition $\\sum_{i=1}^m x_i - m = 0$, we have:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\frac{x_1}{1} = \\frac{x_2}{2} = \\dots = \\frac{x_m}{m} \\\\\n",
    "\\sum_{i=1}^m x_i = m\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can solve this by noting that: $x_1 = \\frac{x_a}{a} \\forall 1 \\leq a \\leq m$ \n",
    "\n",
    "and rewrite the sum:\n",
    "$$\n",
    "\\sum_{i=1}^m x_i = m \\Rightarrow \\sum_{i=1}^m ix_1 = m \\\\~\\\\\n",
    "\\Rightarrow \\frac{m(m+1)}{2} x_1 = m \\Rightarrow x_1 = \\frac{2}{m + 1}\n",
    "$$\n",
    "\n",
    "and evaluate the other $x$ values ($x_2, x_3, \\dots, x_m)$ to get the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so let's test this via code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4112.08500285362"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def P(x: list[float]) -> float:\n",
    "    t = 1.0\n",
    "    for i, v in enumerate(x):\n",
    "        t *= math.pow(v, i + 1)\n",
    "    return t\n",
    "\n",
    "def assumed_optimal_list(m: int) -> list[float]:\n",
    "    x1 = 2 / (m + 1)\n",
    "    res: list[float] = []\n",
    "    res.append(x1)\n",
    "    for i in range(2, m + 1):\n",
    "        res.append(x1 * i)\n",
    "    assert len(res) == m\n",
    "    return res\n",
    "\n",
    "P(assumed_optimal_list(10))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371048281"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "for i in range(2, 15 + 1):\n",
    "    n += int(P(assumed_optimal_list(i)))\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We acknowledged above that \n",
    "\n",
    "$$\n",
    "$4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Callable\n",
    "import math\n",
    "import sys\n",
    "def partial_derivative(f: Callable[[list[float]], float], x: list[float], n: int) -> float:\n",
    "    n -= 1\n",
    "    h = math.sqrt(sys.float_info.epsilon)\n",
    "    y = x.copy()\n",
    "    y[n] += h\n",
    "    return (f(y) - f(x)) / h\n",
    "\n",
    "partial_derivative(P, [1, 2, 2], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def P_partial_derivative(x: list[float], a: int) -> float:\n",
    "    # note that we still use index from 1 to shift the index\n",
    "    return a / x[a - 1] * P(x)\n",
    "\n",
    "# P([1, 2])\n",
    "P_partial_derivative([1, 3], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0, 4.0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def P_gradient(x: list[float]) -> list[float]:\n",
    "    z = P(x)\n",
    "    return [(i + 1) / x[i] * z for i in range(len(x))]\n",
    "\n",
    "P_gradient([1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we consider a small possibility. Suppose we have a small vector $X$, and gradient $\\nabla$, we want to find a learning rate $\\alpha$ such that if we take the result $Y = X - \\alpha\\nabla$ it still remains in the space, so we have\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^m (X_i - \\alpha\\nabla_i) = m \\\\~\\\\ \n",
    "\\Rightarrow \\sum_{i=1}^m X_i = m + \\sum_{i=1}^m \\alpha\\nabla_i = m  + \\alpha\\sum_{i=1}^m \\nabla_i \\\\~\\\\\n",
    "$$\n",
    "\n",
    "wait nvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1092139060.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef P_gradient_ascent(x0: list[float], iter: int, lr: float) -> tuple[list[float], float]:\u001b[39m\n                                                                                              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def P_gradient_ascent(x0: list[float], iter: int = 10 ** 3, lr: float = 0.01) -> tuple[list[float], float]:\n",
    "    # optimize the P-function, based on the requirement\n",
    "    for _ in range(iter):\n",
    "        grad = P_gradient(x0)\n",
    "        # we customize the learning rate alpha to keep the list x0 in the plane of \\sum__{i=1}^n = m \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
